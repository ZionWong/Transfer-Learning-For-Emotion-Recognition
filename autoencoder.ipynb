{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow.contrib.slim as slim\n",
    "import cPickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "get_ipython().magic(u'matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 获取数据，并且对特征进行标准化处理，同时将目标域数据进行切分，得到训练集和测试集\n",
    "def get_data():\n",
    "    with open('./feature/casia_988_feature.pkl') as f:\n",
    "        casia = cPickle.load(f)\n",
    "    with open('./feature/southeast_988_feature.pkl') as f:\n",
    "        se = cPickle.load(f)\n",
    "    return casia,se\n",
    "\n",
    "\n",
    "casia,se = get_data()   ## se表示实验室自己录的数据\n",
    "\n",
    "casia_tr = StandardScaler()\n",
    "casia['data'] = casia_tr.fit_transform(casia['data'])\n",
    "\n",
    "se_tr = StandardScaler()\n",
    "se['data'] = se_tr.fit_transform(se['data'])\n",
    "\n",
    "trX,teX,trY,teY = train_test_split(casia['data'],casia['label'],test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##构建自编码器并进行训练\n",
    "input_dim = 988\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, input_dim], name='input')\n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "def model(X):\n",
    "    encoder_fc1 = slim.fully_connected(X,768,normalizer_fn=slim.batch_norm,activation_fn=tf.nn.relu,scope='encoder_fc1',weights_initializer=initializer)\n",
    "    encoder_fc2 = slim.fully_connected(encoder_fc1,512,normalizer_fn=slim.batch_norm,activation_fn=tf.nn.relu,scope='encoder_fc2',weights_initializer=initializer)\n",
    "    decoder_fc1 = slim.fully_connected(encoder_fc2,768,normalizer_fn=slim.batch_norm,activation_fn=tf.nn.relu,scope='decoder_fc1',weights_initializer=initializer)\n",
    "    decoder_fc2 = slim.fully_connected(decoder_fc1,input_dim,normalizer_fn=None,activation_fn=None,scope='decoder_fc2',weights_initializer=initializer)\n",
    "    return decoder_fc2,encoder_fc2\n",
    "\n",
    "Z,enc_feature = model(X)  #enc_feature是利用自编码器对数据进行特征提取的接口\n",
    "\n",
    "cost = tf.reduce_sum(tf.pow(X - Z, 2))  \n",
    "train_op = tf.train.AdamOptimizer(0.0005).minimize(cost)\n",
    "predict_op = Z\n",
    "\n",
    "sess = tf.InteractiveSession()  #如果是用python而不是ipython的话，注意将InteractiveSession()替换为Session()\n",
    "tf.global_variables_initializer().run()\n",
    "batch = 30\n",
    "for i in range(500):\n",
    "    trX,trY = shuffle(trX,trY)\n",
    "    for start, end in zip(range(0, len(trX), batch), range(batch, len(trX)+1, batch)):\n",
    "        input_ = trX[start:end]\n",
    "        sess.run(train_op, feed_dict={X: input_})\n",
    "    print(\"epoch: {0}\".format(i),\"train_loss: {0}\".format(sess.run(cost, feed_dict={X: trX})),\n",
    "          \"   test_loss: {0}\".format(sess.run(cost, feed_dict={X: teX})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "casia_train = sess.run(enc_feature,feed_dict={X:trX}) ##利用自编码器得到casia训练集的变换特征\n",
    "casia_test = sess.run(enc_feature,feed_dict={X:teX})##利用自编码器得到casia测试集的变换特征\n",
    "se_train = sess.run(enc_feature,feed_dict={X:se['data']})##利用自编码器得到实验室数据集的变换特征\n",
    "\n",
    "tag_transform = LabelEncoder()   ##对标签进行变换\n",
    "casia_train_y = tag_transform.fit_transform(trY)\n",
    "casia_test_y = tag_transform.transform(teY)\n",
    "se_y = tag_transform.transform(se['label'])\n",
    "se_train,se_y = shuffle(se_train,se_y)\n",
    "\n",
    "train_percent = 1  #控制casia训练集中用于训练分类器的数据的比例\n",
    "train_x = np.vstack([casia_train[0:int(train_percent*len(casia_train))],se_train])\n",
    "train_y = np.concatenate([casia_train_y[0:int(train_percent*len(casia_train_y))],se_y])\n",
    "\n",
    "train = {'data':train_x,'label':train_y}\n",
    "test = {'data':casia_test,'label':casia_test_y}\n",
    "\n",
    "## 保存训练数据与测试数据\n",
    "with open('./transfer_feature/train.pkl','w') as f:\n",
    "    cPickle.dump(train,f)\n",
    "\n",
    "\n",
    "with open('./transfer_feature/test.pkl','w') as f:\n",
    "    cPickle.dump(test,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
